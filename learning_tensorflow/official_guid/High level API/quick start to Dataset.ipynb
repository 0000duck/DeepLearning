{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick start to Dataset\n",
    "\n",
    "The [tf.data](https://www.tensorflow.org/api_docs/python/tf/data) module contains a collection of classes that allows you to easily load data, manipulate it, and pipe it into your model. This document introduces the API by walking through two simple examples:\n",
    "\n",
    "  * Reading in-memory data from numpy arrays.\n",
    "  * Reading lines from a csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import iris_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch iris and mnist as example dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
      "0          6.4         2.8          5.6         2.2\n",
      "1          5.0         2.3          3.3         1.0\n",
      "2          4.9         2.5          4.5         1.7\n",
      "3          4.9         3.1          1.5         0.1\n",
      "4          5.7         3.8          1.7         0.3\n",
      "<class 'pandas.core.series.Series'>\n",
      "0    2\n",
      "1    1\n",
      "2    2\n",
      "3    0\n",
      "4    0\n",
      "Name: Species, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fetch the iris_data\n",
    "iris_train, iris_test = iris_data.load_data()\n",
    "iris_features, iris_labels = iris_train\n",
    "print(type(iris_features))\n",
    "print(iris_features.head())\n",
    "print(type(iris_labels))\n",
    "print(iris_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Fetch the mnist_data\n",
    "mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()\n",
    "mnist_X, mnist_y = mnist_train\n",
    "print(type(mnist_X))\n",
    "print(mnist_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.data.Dataset.from_tensor_slices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ({SepalLength: (), SepalWidth: (), PetalLength: (), PetalWidth: ()}, ()), types: ({SepalLength: tf.float64, SepalWidth: tf.float64, PetalLength: tf.float64, PetalWidth: tf.float64}, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "iris_ds = tf.data.Dataset.from_tensor_slices((dict(iris_features), iris_labels))\n",
    "print(iris_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: {SepalLength: (), SepalWidth: (), PetalLength: (), PetalWidth: ()}, types: {SepalLength: tf.float64, SepalWidth: tf.float64, PetalLength: tf.float64, PetalWidth: tf.float64}>\n"
     ]
    }
   ],
   "source": [
    "iris_ds_fs = tf.data.Dataset.from_tensor_slices(dict(iris_features))\n",
    "print(iris_ds_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (28, 28), types: tf.uint8>\n"
     ]
    }
   ],
   "source": [
    "mnist_ds_X = tf.data.Dataset.from_tensor_slices(mnist_X)\n",
    "print(mnist_ds_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Dataset from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/liuweijie/.keras/datasets/iris_training.csv\n",
      "/Users/liuweijie/.keras/datasets/iris_test.csv\n"
     ]
    }
   ],
   "source": [
    "iris_train_path, iris_test_path = iris_data.maybe_download()\n",
    "print(iris_train_path)\n",
    "print(iris_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by building a `TextLineDataset` object to read the file one line at a time. Then, we call the skip method to skip over the first line of the file, which contains a header, not an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SkipDataset shapes: (), types: tf.string>\n"
     ]
    }
   ],
   "source": [
    "iris_train_ds = tf.data.TextLineDataset(iris_train_path).skip(1)\n",
    "print(iris_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
